{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0135abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics\n",
    "\n",
    "# to avoid future warnings for sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982ec606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset.shape: (1500, 117)\n",
      "X.shape: (1500, 103)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Att1</th>\n",
       "      <th>Att2</th>\n",
       "      <th>Att3</th>\n",
       "      <th>Att4</th>\n",
       "      <th>Att5</th>\n",
       "      <th>Att6</th>\n",
       "      <th>Att7</th>\n",
       "      <th>Att8</th>\n",
       "      <th>Att9</th>\n",
       "      <th>Att10</th>\n",
       "      <th>...</th>\n",
       "      <th>Att94</th>\n",
       "      <th>Att95</th>\n",
       "      <th>Att96</th>\n",
       "      <th>Att97</th>\n",
       "      <th>Att98</th>\n",
       "      <th>Att99</th>\n",
       "      <th>Att100</th>\n",
       "      <th>Att101</th>\n",
       "      <th>Att102</th>\n",
       "      <th>Att103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.139771</td>\n",
       "      <td>0.062774</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.083873</td>\n",
       "      <td>-0.119156</td>\n",
       "      <td>0.073305</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.043477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039048</td>\n",
       "      <td>-0.018712</td>\n",
       "      <td>-0.034711</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.039102</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>-0.052659</td>\n",
       "      <td>-0.042402</td>\n",
       "      <td>0.118473</td>\n",
       "      <td>0.125632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.022711</td>\n",
       "      <td>-0.050504</td>\n",
       "      <td>-0.035691</td>\n",
       "      <td>-0.065434</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>-0.378560</td>\n",
       "      <td>0.038212</td>\n",
       "      <td>0.085770</td>\n",
       "      <td>0.182613</td>\n",
       "      <td>-0.055544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001198</td>\n",
       "      <td>0.030594</td>\n",
       "      <td>-0.021814</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>-0.013809</td>\n",
       "      <td>-0.009248</td>\n",
       "      <td>-0.027318</td>\n",
       "      <td>-0.014191</td>\n",
       "      <td>0.022783</td>\n",
       "      <td>0.123785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.090407</td>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.208712</td>\n",
       "      <td>0.102752</td>\n",
       "      <td>0.119315</td>\n",
       "      <td>0.041729</td>\n",
       "      <td>-0.021728</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>-0.063853</td>\n",
       "      <td>-0.053756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195777</td>\n",
       "      <td>0.022294</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>-0.002072</td>\n",
       "      <td>-0.010981</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>-0.063378</td>\n",
       "      <td>-0.084181</td>\n",
       "      <td>-0.034402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.085235</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>0.094063</td>\n",
       "      <td>-0.013592</td>\n",
       "      <td>-0.030719</td>\n",
       "      <td>-0.116062</td>\n",
       "      <td>-0.131674</td>\n",
       "      <td>-0.165448</td>\n",
       "      <td>-0.123053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>-0.066241</td>\n",
       "      <td>-0.046999</td>\n",
       "      <td>-0.066604</td>\n",
       "      <td>-0.055773</td>\n",
       "      <td>-0.041941</td>\n",
       "      <td>0.051066</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.193972</td>\n",
       "      <td>0.131866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.088765</td>\n",
       "      <td>-0.026743</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>-0.043819</td>\n",
       "      <td>-0.005465</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>-0.055865</td>\n",
       "      <td>-0.071484</td>\n",
       "      <td>-0.159025</td>\n",
       "      <td>-0.111348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035045</td>\n",
       "      <td>-0.080882</td>\n",
       "      <td>0.028468</td>\n",
       "      <td>-0.073576</td>\n",
       "      <td>0.050630</td>\n",
       "      <td>0.084832</td>\n",
       "      <td>-0.019570</td>\n",
       "      <td>-0.021650</td>\n",
       "      <td>-0.068326</td>\n",
       "      <td>-0.091155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Att1      Att2      Att3      Att4      Att5      Att6      Att7  \\\n",
       "0  0.093700  0.139771  0.062774  0.007698  0.083873 -0.119156  0.073305   \n",
       "1 -0.022711 -0.050504 -0.035691 -0.065434 -0.084316 -0.378560  0.038212   \n",
       "2 -0.090407  0.021198  0.208712  0.102752  0.119315  0.041729 -0.021728   \n",
       "3 -0.085235  0.009540 -0.013228  0.094063 -0.013592 -0.030719 -0.116062   \n",
       "4 -0.088765 -0.026743  0.002075 -0.043819 -0.005465  0.004306 -0.055865   \n",
       "\n",
       "       Att8      Att9     Att10  ...     Att94     Att95     Att96     Att97  \\\n",
       "0  0.005510  0.027523  0.043477  ...  0.039048 -0.018712 -0.034711 -0.038675   \n",
       "1  0.085770  0.182613 -0.055544  ... -0.001198  0.030594 -0.021814  0.010430   \n",
       "2  0.019603 -0.063853 -0.053756  ...  0.195777  0.022294  0.012583  0.002233   \n",
       "3 -0.131674 -0.165448 -0.123053  ...  0.001189 -0.066241 -0.046999 -0.066604   \n",
       "4 -0.071484 -0.159025 -0.111348  ... -0.035045 -0.080882  0.028468 -0.073576   \n",
       "\n",
       "      Att98     Att99    Att100    Att101    Att102    Att103  \n",
       "0 -0.039102  0.017429 -0.052659 -0.042402  0.118473  0.125632  \n",
       "1 -0.013809 -0.009248 -0.027318 -0.014191  0.022783  0.123785  \n",
       "2 -0.002072 -0.010981  0.007615 -0.063378 -0.084181 -0.034402  \n",
       "3 -0.055773 -0.041941  0.051066  0.004976  0.193972  0.131866  \n",
       "4  0.050630  0.084832 -0.019570 -0.021650 -0.068326 -0.091155  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape: (1500, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class1</th>\n",
       "      <th>Class2</th>\n",
       "      <th>Class3</th>\n",
       "      <th>Class4</th>\n",
       "      <th>Class5</th>\n",
       "      <th>Class6</th>\n",
       "      <th>Class7</th>\n",
       "      <th>Class8</th>\n",
       "      <th>Class9</th>\n",
       "      <th>Class10</th>\n",
       "      <th>Class11</th>\n",
       "      <th>Class12</th>\n",
       "      <th>Class13</th>\n",
       "      <th>Class14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class1 Class2 Class3 Class4 Class5 Class6 Class7 Class8 Class9 Class10  \\\n",
       "0   b'0'   b'0'   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "1   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'   b'1'   b'1'   b'0'    b'0'   \n",
       "2   b'0'   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "3   b'0'   b'0'   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "4   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "\n",
       "  Class11 Class12 Class13 Class14  \n",
       "0    b'0'    b'0'    b'0'    b'0'  \n",
       "1    b'0'    b'1'    b'1'    b'0'  \n",
       "2    b'0'    b'1'    b'1'    b'0'  \n",
       "3    b'0'    b'1'    b'1'    b'1'  \n",
       "4    b'0'    b'0'    b'0'    b'0'  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive stats:\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.io import arff\n",
    "data, meta = scipy.io.arff.loadarff(r'C:\\Users\\pinkpigma\\pinkpigma的同步盘\\KDD研二上\\jupyter\\yeast\\yeast-train.arff')\n",
    "dataset = pd.DataFrame(data)\n",
    "print(\"Dataset.shape: \" + str(dataset.shape))\n",
    "\n",
    "# split the features-X and class labels-y\n",
    "X = dataset.iloc[:, :103]\n",
    "y = dataset.iloc[:, 103:]\n",
    "\n",
    "\n",
    "print(\"X.shape: \" + str(X.shape))\n",
    "display(X.head())\n",
    "print(\"y.shape: \" + str(y.shape))\n",
    "display(y.head())\n",
    "print(\"Descriptive stats:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2974e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1050, 103)\n",
      "X_test.shape: (450, 103)\n",
      "y_train.shape: (1050, 14)\n",
      "y_test.shape: (450, 14)\n"
     ]
    }
   ],
   "source": [
    "X = (X-X.min())/(X.max()-X.min())\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)\n",
    "\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"y_train.shape: \" + str(y_train.shape))\n",
    "print(\"y_test.shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a1f72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression()):\n",
    "        self.base_classifier=base_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a Binary Relevance classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples, n_labels] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        \"\"\"\n",
    "\n",
    "        # list of individual classifiers\n",
    "        self.models = []\n",
    "       \n",
    "        # for every class label\n",
    "        for label in list(y.columns):\n",
    "            # Check that X and y have correct shape\n",
    "            x_checked, y_checked = check_X_y(X, y[label])\n",
    "            # every classifier is independent of the others\n",
    "            # hence we create a copy of the base classifier instance\n",
    "            base_model = clone(self.base_classifier)\n",
    "            # fit the base model - one model each for Y1, Y2....Y14\n",
    "            basel_model = base_model.fit(x_checked, y_checked)\n",
    "            # add the fitted model list of individual classifiers\n",
    "            self.models.append(base_model)\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i=0\n",
    "        # list of individual classifier predictions\n",
    "        preds = []\n",
    "        \n",
    "        # predict against each fitted model - one model per label\n",
    "        for model in self.models:\n",
    "            pred = model.predict(X)\n",
    "            # add the prediction to the dataframe\n",
    "            preds.append(pd.DataFrame({'Class'+ str(i+1): pred}))\n",
    "            i+=1\n",
    "        \n",
    "        # dataframe with predictions for all class labels\n",
    "        all_preds = pd.concat(preds, axis=1)\n",
    "        # standard sklearn classifiers return predictions as numpy arrays\n",
    "        # hence convert the dataframe to a numpy array\n",
    "        return all_preds.to_numpy()\n",
    "    \n",
    "\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        all_preds = pd.DataFrame()\n",
    "        i = 0\n",
    "        \n",
    "        for model in self.models:\n",
    "            # Call predict_proba of the each base model\n",
    "            pred = model.predict_proba(X)\n",
    "            # Add the probabilities of 1 to the dataframe\n",
    "            all_preds['Class'+str(i+1)] = [one_prob[1] for one_prob in pred]\n",
    "            i+=1\n",
    "        \n",
    "        #return probabilities\n",
    "        return all_preds.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24386e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_test, y_pred):\n",
    "    # y_pred is a numpy array, y_test is a dataframe\n",
    "    # to compare the two, convert to a single type\n",
    "    y_test = y_test.to_numpy()\n",
    "    \n",
    "    # shape of test and preds must be equal\n",
    "    assert y_test.shape == y_pred.shape\n",
    "    i=0\n",
    "    # list of scores for each training sample\n",
    "    scores = []\n",
    "    \n",
    "    # for each test sample\n",
    "    while i < len(y_test):\n",
    "        count=0\n",
    "        # count the number of matches in the sample\n",
    "        # y_test[i] -> row values in test set (true values)\n",
    "        # y_pred[i] -> row values in predictions set (predicted values)\n",
    "        for p, q in zip(y_test[i], y_pred[i]):\n",
    "            if p == q:\n",
    "                count += 1\n",
    "\n",
    "        # accuracy score for the sample = no. of correctly predicted labels/total no. of labels\n",
    "        scores.append(count / y_pred.shape[1])\n",
    "        i+=1 \n",
    "\n",
    "    # final accuracy = avg. accuracy over all test samples =\n",
    "    # sum of the accuracy of all training samples/no. of training samples\n",
    "    return round((sum(scores)/len(y_test)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce33d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierChains(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_classifier=LogisticRegression(max_iter=20000), order=None):\n",
    "        self.base_classifier=base_classifier\n",
    "        self.order = order\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Build a Classifier Chain from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "            to a sparse ``csc_matrix``.\n",
    "        y : array-like, shape = [n_samples, n_labels] \n",
    "            The target values (class labels) as integers or strings.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # check the order parameter\n",
    "        if self.order is None:\n",
    "            # default value - natural order for number of labels\n",
    "            self.order = list(range(y.shape[1]))\n",
    "        elif self.order == 'random':\n",
    "            # random order\n",
    "            self.order = list(range(y.shape[1]))\n",
    "            random.shuffle(self.order)\n",
    "        else:\n",
    "            # order specified\n",
    "            if(len(self.order)==y.shape[1]):\n",
    "                # expect order from 1, hence reduce 1 to consider zero indexing\n",
    "                self.order = [o - 1 for o in self.order]\n",
    "    \n",
    "        \n",
    "        # list of base models for each class\n",
    "        self.models = [clone(self.base_classifier) for clf in range(y.shape[1])]\n",
    "\n",
    "        # create a copy of X\n",
    "        X_joined = X.copy()\n",
    "       # X_joined.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # create a new dataframe with X and y-in the order specified\n",
    "        # if order = [2,4,5,6...] -> X_joined= X, y2, y4, y5...\n",
    "        for val in self.order:\n",
    "            X_joined = pd.concat([X_joined, y['Class'+str(val+1)]], axis=1)\n",
    "\n",
    "        \n",
    "        # for each ith model, fit the model on X + y0 to yi-1 (in the order specified)\n",
    "        # if order = [2,4,6,....] fit 1st model on X for y2, fit second model on X+y2 for y4...\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            # select values of the class in order\n",
    "            y_vals = y.loc[:, 'Class'+str(self.order[chain_index]+1)]\n",
    "            # pick values for training - X+y upto the current label\n",
    "            t_X = X_joined.iloc[:, :(X.shape[1]+chain_index)]\n",
    "            check_X_y(t_X, y_vals)\n",
    "            # fit the model\n",
    "            model.fit(t_X, y_vals)\n",
    "\n",
    "\n",
    "            \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # dataframe to maintain previous predictions\n",
    "        pred_chain = pd.DataFrame(columns=['Class'+str(o+1) for o in self.order])\n",
    "        \n",
    "        X_copy = X.copy()\n",
    "        X_joined = X.copy()\n",
    "        \n",
    "        # use default indexing\n",
    "        X_joined.reset_index(drop=True, inplace=True)\n",
    "        X_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        i=0\n",
    "        \n",
    "        # for each ith model, predict based on X + predictions of all models upto i-1\n",
    "        # happens in the specified order since models are already fitted according to the order\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            # select previous predictions - all columns upto the current index\n",
    "            prev_preds = pred_chain.iloc[:, :chain_index]\n",
    "            # join the previous predictions with X\n",
    "            X_joined = pd.concat([X_copy, prev_preds], axis=1)\n",
    "            # predict on the base model\n",
    "            pred = model.predict(X_joined)\n",
    "            # add the new prediction to the pred chain\n",
    "            pred_chain['Class'+str(self.order[i]+1)] = pred\n",
    "            i+=1\n",
    "\n",
    "        # re-arrange the columns in natural order to return the predictions\n",
    "        pred_chain = pred_chain.loc[:, ['Class'+str(j+1) for j in range(0, len(self.order))]]\n",
    "        # all sklearn implementations return numpy array\n",
    "        # hence convert the dataframe to numpy array\n",
    "        return pred_chain.to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Function to predict probabilities of 1s\n",
    "    def predict_proba(self, X):\n",
    "        # check if the models list has been set up\n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # dataframe to maintain previous predictions\n",
    "        pred_chain = pd.DataFrame(columns=['Class'+str(o+1) for o in self.order])\n",
    "        # dataframe to maintain probabilities of class labels\n",
    "        pred_probs = pd.DataFrame(columns=['Class'+str(o+1) for o in self.order])\n",
    "        X_copy = X.copy()\n",
    "        X_joined = X.copy()\n",
    "        \n",
    "        # use default indexing\n",
    "        X_joined.reset_index(drop=True, inplace=True)\n",
    "        X_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        i=0\n",
    "        \n",
    "        # for each ith model, predict based on X + predictions of all models upto i-1\n",
    "        # happens in the specified order since models are already fitted according to the order\n",
    "        for chain_index, model in enumerate(self.models):\n",
    "            \n",
    "            # select previous predictions - all columns upto the current index\n",
    "            prev_preds = pred_chain.iloc[:, :chain_index]\n",
    "            # join the previous predictions with X\n",
    "            X_joined = pd.concat([X_copy, prev_preds], axis=1)\n",
    "            # predict on the base model\n",
    "            pred = model.predict(X_joined)\n",
    "            # predict probabilities\n",
    "            pred_proba = model.predict_proba(X_joined)\n",
    "            # add the new prediction to the pred chain\n",
    "            pred_chain['Class'+str(self.order[i]+1)] = pred\n",
    "            # save the probabilities of 1 according to label order\n",
    "            pred_probs['Class'+str(self.order[i]+1)] = [one_prob[1] for one_prob in pred_proba]\n",
    "            i+=1\n",
    "\n",
    "        # re-arrange the columns in natural order to return the probabilities\n",
    "        pred_probs = pred_probs.loc[:, ['Class'+str(j+1) for j in range(0, len(self.order))]]\n",
    "        # all sklearn implementations return numpy array\n",
    "        # hence convert the dataframe to numpy array\n",
    "        return pred_probs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f448dc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PINKPI~1\\AppData\\Local\\Temp/ipykernel_24636/1710797709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec0b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
